(window.webpackJsonp=window.webpackJsonp||[]).push([[74],{148:function(e,n,r){"use strict";r.r(n),r.d(n,"frontMatter",(function(){return c})),r.d(n,"metadata",(function(){return s})),r.d(n,"toc",(function(){return l})),r.d(n,"default",(function(){return f}));var t=r(3),o=r(7),i=(r(0),r(337)),a=["components"],c={id:"reinforcement-learning",title:"Reinforcement Learning",description:"Reinforcement Learning",sidebar_label:"Reinforcement Learning",featured:!0,rank:23},s={unversionedId:"glossary/reinforcement-learning",id:"glossary/reinforcement-learning",isDocsHomePage:!1,title:"Reinforcement Learning",description:"Reinforcement Learning",source:"@site/docs/glossary/reinforcement-learning.md",slug:"/glossary/reinforcement-learning",permalink:"/docs/glossary/reinforcement-learning",version:"current",sidebar_label:"Reinforcement Learning",sidebar:"glossary",previous:{title:"Quality Assurance",permalink:"/docs/glossary/quality-assurance"},next:{title:"Self-service Routing",permalink:"/docs/glossary/self-service-routing"}},l=[],u={toc:l};function f(e){var n=e.components,r=Object(o.a)(e,a);return Object(i.b)("wrapper",Object(t.a)({},u,r,{components:n,mdxType:"MDXLayout"}),Object(i.b)("p",null,"Reinforcement learning (RL) is a type of machine learning where the learning system receives training only in terms of rewards and punishments. It then attempts to foster actions or situations for which the overall reward is maximized and the punishments are minimized."))}f.isMDXComponent=!0},337:function(e,n,r){"use strict";r.d(n,"a",(function(){return f})),r.d(n,"b",(function(){return y}));var t=r(0),o=r.n(t);function i(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function a(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function c(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?a(Object(r),!0).forEach((function(n){i(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function s(e,n){if(null==e)return{};var r,t,o=function(e,n){if(null==e)return{};var r,t,o={},i=Object.keys(e);for(t=0;t<i.length;t++)r=i[t],n.indexOf(r)>=0||(o[r]=e[r]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)r=i[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=o.a.createContext({}),u=function(e){var n=o.a.useContext(l),r=n;return e&&(r="function"==typeof e?e(n):c(c({},n),e)),r},f=function(e){var n=u(e.components);return o.a.createElement(l.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return o.a.createElement(o.a.Fragment,{},n)}},m=o.a.forwardRef((function(e,n){var r=e.components,t=e.mdxType,i=e.originalType,a=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),f=u(r),m=t,y=f["".concat(a,".").concat(m)]||f[m]||p[m]||i;return r?o.a.createElement(y,c(c({ref:n},l),{},{components:r})):o.a.createElement(y,c({ref:n},l))}));function y(e,n){var r=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var i=r.length,a=new Array(i);a[0]=m;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:t,a[1]=c;for(var l=2;l<i;l++)a[l]=r[l];return o.a.createElement.apply(null,a)}return o.a.createElement.apply(null,r)}m.displayName="MDXCreateElement"}}]);